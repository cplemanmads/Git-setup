{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test, optimize, and analyze the performance of a classification model using a methodology of your choice for the randomly generated moons dataset.\n",
    "\n",
    "You are not being evaluated for the performance of your model. Instead, we are interested in whether you can implement a simple but rigorous ML workflow.\n",
    "\n",
    "Show all of your work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are free to use any package you deem fit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, Y = make_moons(random_state=42, n_samples=(50, 450), noise=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Inspection\n",
    "Let's check the `X` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the data is an array and return it's shape\n",
    "X = np.asarray(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a 2D array. Let's run some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mean, Median, and IQR of dataset; determining of there's need of a scaler\n",
    "plt.boxplot(X, labels = ['X[0]', 'X[1]'], showmeans = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the Y data is one's and zero's, so we don't need to inspect that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(final, initial):\n",
    "    return 100 * (final - initial) / initial\n",
    "\n",
    "def solver_performance(solver_name):\n",
    "    model = LogisticRegression(solver = solver_name).fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_test,y_test)\n",
    "\n",
    "def multi_class_performance(multi_class_name):\n",
    "    model = LogisticRegression(multi_class = multi_class_name).fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_test,y_test)\n",
    "\n",
    "def intercept_performance(intercept_value):\n",
    "    model = LogisticRegression(C = intercept_value).fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_test,y_test)\n",
    "\n",
    "# Note that func has to be one of the functions with the name *_performance\n",
    "def create_custom_dict(arr, func):\n",
    "    return {i: func(i) for i in arr}\n",
    "\n",
    "def performance_change(performance_dict, base_values):\n",
    "    train = {method: performance_dict[method][0] - base_values[0] for method in performance_dict}\n",
    "    test = {method: performance_dict[method][1] - base_values[1] for method in performance_dict}\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing a testing size of 30% because we have enough training data\n",
    "# random_state is set to 42 because it was set to 42 in the make_moons() method\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is: (350, 2)\n",
      "y_train shape is: (350,)\n"
     ]
    }
   ],
   "source": [
    "#Ensuring training size is as expexted\n",
    "print('X_train shape is: ' + str(X_train.shape))\n",
    "print('y_train shape is: ' + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the base model\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228571428571428"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model training score\n",
    "model_base_train = model.score(X_train, y_train)\n",
    "model_base_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model testing score\n",
    "model_base_test = model.score(X_test, y_test)\n",
    "model_base_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_performance = model_base_train, model_base_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over solvers\n",
    "The last model performed quite well on the training data, and generalized well on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'newton-cg': (0.9228571428571428, 0.9533333333333334),\n",
       " 'sag': (0.9228571428571428, 0.9533333333333334),\n",
       " 'saga': (0.9228571428571428, 0.9533333333333334),\n",
       " 'lbfgs': (0.9228571428571428, 0.9533333333333334)}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate an array of solvers to iterate over\n",
    "solvers = np.array(['newton-cg', 'sag', 'saga', 'lbfgs'])\n",
    "\n",
    "# Initialize and append results to a dictionary\n",
    "solver_performances = create_custom_dict(solvers, solver_performance)\n",
    "\n",
    "# Return results\n",
    "solver_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the solver had no discernable effect on the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in train:{'newton-cg': 0.0, 'sag': 0.0, 'saga': 0.0, 'lbfgs': 0.0}\n",
      "Change in test:{'newton-cg': 0.0, 'sag': 0.0, 'saga': 0.0, 'lbfgs': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the change in performance from the base model to models incorporating each solver\n",
    "change_in_train, change_in_test = performance_change(solver_performances, model_base_performance)\n",
    "print('Change in train:' + str(change_in_train))\n",
    "print('Change in test:' + str(change_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over multi_class arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array of multi_class arguments to iterate over\n",
    "multi_class_names = np.array(['auto', 'ovr', 'multinomial'])\n",
    "\n",
    "# Initialize and append results to a dictionary\n",
    "multi_class_performances = create_custom_dict(multi_class_names, multi_class_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto': (0.9228571428571428, 0.9533333333333334),\n",
       " 'ovr': (0.9228571428571428, 0.9533333333333334),\n",
       " 'multinomial': (0.9257142857142857, 0.9533333333333334)}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return results\n",
    "multi_class_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a minor improvement in test performance when using the `multinomial` argument for the `multi_class` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in train:{'auto': 0.0, 'ovr': 0.0, 'multinomial': 0.0028571428571428914}\n",
      "Change in test:{'auto': 0.0, 'ovr': 0.0, 'multinomial': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the change in performance from the base model to models incorporating each multi_class argument\n",
    "change_in_train, change_in_test = performance_change(multi_class_performances, model_base_performance)\n",
    "print('Change in train:' + str(change_in_train))\n",
    "print('Change in test:' + str(change_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating over different intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array of intercepts to iterate over\n",
    "intercepts = np.arange(0.01,1.0,.1)\n",
    "\n",
    "# Initialize and append results to a dictionary\n",
    "intercept_performances = create_custom_dict(intercepts, intercept_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return results\n",
    "intercept_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the change in performance from the base model to models incorporating each multi_class argument\n",
    "change_in_train, change_in_test = performance_change(intercept_performances, model_base_performance)\n",
    "print('Change in train:' + str(change_in_train))\n",
    "print('Change in test:' + str(change_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Independent Variables (X[0] and X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import method\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the training and testing X data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Fit the base model\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228571428571428"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model training score\n",
    "model_base_train = model.score(X_train_scaled, y_train)\n",
    "model_base_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model testing score\n",
    "model_base_test = model.score(X_test_scaled, y_test)\n",
    "model_base_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance does not change after normalizing the X data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LogisticRegression in the sklearn.linear_model library yielded a high training score of .9229, and a testing score of .9533. This indicated the model fit the data well in testing and was generalizable to the testing data. Although performance was already quite high, attempts at optimization included changing the solver, multi_class, and intercept parameters, along with using the StandardScaler object to normalize the indedependent variables. Through each of these attempts, the testing performance did not improve. However, this model has performed well with each modification. Further testing (with new data) would be useful to see if the model maintains its precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
